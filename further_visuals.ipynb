{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import threading\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "from tqdm import tqdm, tqdm_notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What I did here\n",
    "<br>\n",
    "Here, we split the data into 6-months' window (so that the difference of the max and min dates in it will be 6 months) starting from the begining. \n",
    "\n",
    "This looks something like this:\n",
    "\n",
    "               \n",
    "                         -------------------------->                     ------------>\n",
    "                      -------------------------->                     ------------>\n",
    "                   ------------------------->                     ------------>\n",
    "                __________   ___________   ___________   _______   ____________\n",
    "              _/ 3 window \\_/ 33 window \\_/ 63 window \\_/ ..... \\_/ N+3 window \\_\n",
    "            __________   ___________   ___________   _______   ____________\n",
    "          _/ 2 window \\_/ 32 window \\_/ 62 window \\_/ ..... \\_/ N+1 window \\_\n",
    "        __________   ___________   ___________   _______   __________\n",
    "      _/ 1 window \\_/ 31 window \\_/ 61 window \\_/ ..... \\_/ N window \\_\n",
    "    1950.01------1950.07------1951.01------1951.07------_____............------2018.01\n",
    "    __________________________________________________________________________________\n",
    "\n",
    "\n",
    "Firstly I split the initial data with 6-months' window and save the resulting data-pieces to .pkl format.\n",
    "\n",
    "After I ready each one and make the coresponding histogram saving it to .npy format (numpy array format).\n",
    "<br> <br> <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data : (948193, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BEGIN_LAT</th>\n",
       "      <th>BEGIN_LON</th>\n",
       "      <th>BEGIN_YEARMONTH</th>\n",
       "      <th>STATE</th>\n",
       "      <th>INJURIES_DIRECT</th>\n",
       "      <th>INJURIES_INDIRECT</th>\n",
       "      <th>DEATHS_DIRECT</th>\n",
       "      <th>DEATHS_INDIRECT</th>\n",
       "      <th>DAMAGE_PROPERTY</th>\n",
       "      <th>EVENT_TYPE</th>\n",
       "      <th>DAMAGE_CROPS</th>\n",
       "      <th>MAGNITUDE</th>\n",
       "      <th>MAGNITUDE_TYPE</th>\n",
       "      <th>FLOOD_CAUSE</th>\n",
       "      <th>DATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35.12</td>\n",
       "      <td>-99.20</td>\n",
       "      <td>195004</td>\n",
       "      <td>OKLAHOMA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>250K</td>\n",
       "      <td>Tornado</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1950-04-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.90</td>\n",
       "      <td>-98.60</td>\n",
       "      <td>195004</td>\n",
       "      <td>TEXAS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25K</td>\n",
       "      <td>Tornado</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1950-04-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40.58</td>\n",
       "      <td>-75.70</td>\n",
       "      <td>195007</td>\n",
       "      <td>PENNSYLVANIA</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25K</td>\n",
       "      <td>Tornado</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1950-07-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40.60</td>\n",
       "      <td>-76.75</td>\n",
       "      <td>195007</td>\n",
       "      <td>PENNSYLVANIA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.5K</td>\n",
       "      <td>Tornado</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1950-07-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.63</td>\n",
       "      <td>-79.68</td>\n",
       "      <td>195007</td>\n",
       "      <td>PENNSYLVANIA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.5K</td>\n",
       "      <td>Tornado</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1950-07-18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   BEGIN_LAT  BEGIN_LON  BEGIN_YEARMONTH         STATE  INJURIES_DIRECT  \\\n",
       "0      35.12     -99.20           195004      OKLAHOMA                0   \n",
       "1      31.90     -98.60           195004         TEXAS                0   \n",
       "2      40.58     -75.70           195007  PENNSYLVANIA                2   \n",
       "3      40.60     -76.75           195007  PENNSYLVANIA                0   \n",
       "4      41.63     -79.68           195007  PENNSYLVANIA                0   \n",
       "\n",
       "   INJURIES_INDIRECT  DEATHS_DIRECT  DEATHS_INDIRECT DAMAGE_PROPERTY  \\\n",
       "0                  0              0                0            250K   \n",
       "1                  0              0                0             25K   \n",
       "2                  0              0                0             25K   \n",
       "3                  0              0                0            2.5K   \n",
       "4                  0              0                0            2.5K   \n",
       "\n",
       "  EVENT_TYPE DAMAGE_CROPS  MAGNITUDE MAGNITUDE_TYPE FLOOD_CAUSE        DATE  \n",
       "0    Tornado            0        0.0            NaN         NaN  1950-04-13  \n",
       "1    Tornado            0        0.0            NaN         NaN  1950-04-22  \n",
       "2    Tornado            0        0.0            NaN         NaN  1950-07-11  \n",
       "3    Tornado            0        0.0            NaN         NaN  1950-07-10  \n",
       "4    Tornado            0        0.0            NaN         NaN  1950-07-18  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########################\n",
    "##    Reading data    ##\n",
    "########################\n",
    "\n",
    "data = pd.read_pickle('total_data.pkl')\n",
    "\n",
    "print('data :', data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################\n",
    "##   Froming DIST_FROM_START column for fast splitting   ##\n",
    "###########################################################\n",
    "\n",
    "start = data.DATE.min()\n",
    "data['DIST_FROM_START'] = data.DATE.apply(lambda x: (x-start).days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################\n",
    "##    Split with the given window    ##\n",
    "#######################################\n",
    "\n",
    "def split(data, window):\n",
    "    start = data.DIST_FROM_START.min()   # start of the timeline\n",
    "    finish = data.DIST_FROM_START.max()  # end of the timeline\n",
    "    \n",
    "    splits = []\n",
    "    chunk_count = 0\n",
    "    for date in tqdm(np.arange(start, finish)):\n",
    "        hold = data[np.logical_and(data.DIST_FROM_START>=date, data.DIST_FROM_START<date+window)]\n",
    "        splits.append(hold)\n",
    "    \n",
    "    return splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25193/25193 [02:02<00:00, 193.65it/s]\n"
     ]
    }
   ],
   "source": [
    "##################################################\n",
    "##          This is the most heavy part         ##\n",
    "##    After running, \"splits\" results to 22GB   ##\n",
    "##################################################\n",
    "\n",
    "splits = split(data, 6*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25193it [10:22, 40.47it/s] \n"
     ]
    }
   ],
   "source": [
    "############################################\n",
    "##   Saving the resulting 22 GB of data   ##\n",
    "############################################\n",
    "\n",
    "for i, split in tqdm(enumerate(splits)):\n",
    "    split.to_pickle('splited_data/split_'+str(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "Now we have the 6-month splits and it's time to make the histograms/heatmaps. \n",
    "<br> <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "######################################\n",
    "##    Making the heatmap dataset    ##\n",
    "######################################\n",
    "\n",
    "def make_heatmaps(file_names, save_path):\n",
    "    chunk_count = 0\n",
    "    heatmap_data = []\n",
    "    for file_name in tqdm(file_names):\n",
    "#         print(i+1, 'from', len(file_names))\n",
    "        hold = pd.read_pickle(file_name)\n",
    "        heatmap_data.append(np.histogram2d(hold.BEGIN_LON,hold.BEGIN_LAT,\n",
    "                                           bins=(50, 20),range=[[-130, -64], [24, 50]])[0])\n",
    "#     print('chunk_count :', chunk_count)\n",
    "    np.save(os.path.join(save_path,'heatmaps.npy'), heatmap_data)\n",
    "    print('\\n\\t Done ! \\n\\n') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_names_0 : 6299\n",
      "file_names_1 : 6298\n",
      "file_names_2 : 6298\n",
      "file_names_3 : 6298\n"
     ]
    }
   ],
   "source": [
    "#############################################################\n",
    "##   Seperating the tast to 4 processes(processor cores)   ##\n",
    "#############################################################\n",
    "\n",
    "file_names_0 = []\n",
    "file_names_1 = []\n",
    "file_names_2 = []\n",
    "file_names_3 = []\n",
    "\n",
    "#####################################\n",
    "##   Checking correct indexation   ##\n",
    "#####################################\n",
    "assert (set(map(lambda x: int(x[6:]), os.listdir('splited_data')))==\n",
    "        set(range(min(map(lambda x: int(x[6:]), os.listdir('splited_data'))), \n",
    "                  max(map(lambda x: int(x[6:]), os.listdir('splited_data')))+1)))\n",
    "\n",
    "for i in range(min(map(lambda x: int(x[6:]), os.listdir('splited_data'))), \n",
    "               max(map(lambda x: int(x[6:]), os.listdir('splited_data')))+1):\n",
    "    if i%4==0:\n",
    "        file_names_0.append('splited_data/split_'+str(i))\n",
    "    elif i%4==1:\n",
    "        file_names_1.append('splited_data/split_'+str(i))\n",
    "    elif i%4==2:\n",
    "        file_names_2.append('splited_data/split_'+str(i))\n",
    "    else:\n",
    "        file_names_3.append('splited_data/split_'+str(i))\n",
    "\n",
    "print('file_names_0 :', len(file_names_0))\n",
    "print('file_names_1 :', len(file_names_1))\n",
    "print('file_names_2 :', len(file_names_2))\n",
    "print('file_names_3 :', len(file_names_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6298/6298 [01:37<00:00, 64.52it/s] \n",
      " 99%|█████████▊| 6208/6298 [01:37<00:02, 34.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t Done ! \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 6230/6299 [01:37<00:03, 19.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6298/6298 [01:39<00:00, 63.41it/s]\n",
      "100%|██████████| 6299/6299 [01:39<00:00, 63.36it/s]\n",
      " 99%|█████████▉| 6244/6298 [01:39<00:02, 21.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t Done ! \n",
      "\n",
      "\n",
      "\n",
      "\t Done ! \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6298/6298 [01:40<00:00, 62.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t Done ! \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "################################\n",
    "##    Runing the processes    ##\n",
    "################################\n",
    "\n",
    "p0 = multiprocessing.Process(target=make_heatmaps, args=(file_names_0, 'hist_data/process_0'))\n",
    "p1 = multiprocessing.Process(target=make_heatmaps, args=(file_names_1, 'hist_data/process_1'))\n",
    "p2 = multiprocessing.Process(target=make_heatmaps, args=(file_names_2, 'hist_data/process_2'))\n",
    "p3 = multiprocessing.Process(target=make_heatmaps, args=(file_names_3, 'hist_data/process_3'))\n",
    "\n",
    "p0.start()\n",
    "p1.start()\n",
    "p2.start()\n",
    "p3.start()\n",
    "\n",
    "p0.join()\n",
    "p1.join()\n",
    "p2.join()\n",
    "p3.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
