{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import time\n",
    "import shutil\n",
    "import ftplib\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_data_dir = '../../Data/csv_Data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the data\n",
    "<br>\n",
    "So we now have 3 files per year:\n",
    "\n",
    "    StormEvents_details-ftp_v1.0_dYYYY_cYYYYMMDD.csv\n",
    "    StormEvents_locations-ftp_v1.0_dYYYY_cYYYYMMDD.csv\n",
    "    StormEvents_fatalities-ftp_v1.0_dYYYY_cYYYYMMDD.csv\n",
    "\n",
    "The main information we need is in StormEvents_details-ftp_v1.0_dYYYY_cYYYYMMDD.csv file. <br>\n",
    "Next cell reads them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-th out of 207 files is being processed (StormEvents_details-ftp_v1.0_d1958_c20160223.csv)\n",
      "2-th out of 207 files is being processed (StormEvents_fatalities-ftp_v1.0_d2015_c20180525.csv)\n",
      "3-th out of 207 files is being processed (StormEvents_details-ftp_v1.0_d2011_c20180718.csv)\n",
      "4-th out of 207 files is being processed (StormEvents_locations-ftp_v1.0_d2017_c20190405.csv)\n",
      "5-th out of 207 files is being processed (StormEvents_details-ftp_v1.0_d1957_c20160223.csv)\n",
      "6-th out of 207 files is being processed (StormEvents_locations-ftp_v1.0_d1980_c20170717.csv)\n",
      "7-th out of 207 files is being processed (StormEvents_locations-ftp_v1.0_d1968_c20160223.csv)\n",
      "8-th out of 207 files is being processed (StormEvents_fatalities-ftp_v1.0_d1982_c20160223.csv)\n",
      "9-th out of 207 files is being processed (StormEvents_locations-ftp_v1.0_d1985_c20160223.csv)\n",
      "10-th out of 207 files is being processed (StormEvents_locations-ftp_v1.0_d1977_c20160223.csv)\n",
      "11-th out of 207 files is being processed (StormEvents_locations-ftp_v1.0_d2006_c20170717.csv)\n",
      "12-th out of 207 files is being processed (StormEvents_fatalities-ftp_v1.0_d2014_c20180718.csv)\n",
      "13-th out of 207 files is being processed (StormEvents_fatalities-ftp_v1.0_d2012_c20170519.csv)\n",
      "14-th out of 207 files is being processed (StormEvents_fatalities-ftp_v1.0_d2010_c20170726.csv)\n",
      "15-th out of 207 files is being processed (StormEvents_details-ftp_v1.0_d1968_c20160223.csv)\n",
      "16-th out of 207 files is being processed (StormEvents_details-ftp_v1.0_d1993_c20170717.csv)\n",
      "17-th out of 207 files is being processed (StormEvents_fatalities-ftp_v1.0_d1963_c20160223.csv)\n",
      "18-th out of 207 files is being processed (StormEvents_details-ftp_v1.0_d1988_c20170717.csv)\n",
      "19-th out of 207 files is being processed (StormEvents_details-ftp_v1.0_d2001_c20170717.csv)\n",
      "20-th out of 207 files is being processed (StormEvents_locations-ftp_v1.0_d1979_c20160223.csv)\n",
      "21-th out of 207 files is being processed (StormEvents_fatalities-ftp_v1.0_d1964_c20160223.csv)\n",
      "22-th out of 207 files is being processed (StormEvents_locations-ftp_v1.0_d2004_c20170717.csv)\n",
      "23-th out of 207 files is being processed (StormEvents_fatalities-ftp_v1.0_d1981_c20170717.csv)\n",
      "24-th out of 207 files is being processed (StormEvents_fatalities-ftp_v1.0_d1985_c20160223.csv)\n",
      "25-th out of 207 files is being processed (StormEvents_locations-ftp_v1.0_d2002_c20170717.csv)\n",
      "26-th out of 207 files is being processed (StormEvents_fatalities-ftp_v1.0_d2011_c20180718.csv)\n",
      "27-th out of 207 files is being processed (StormEvents_details-ftp_v1.0_d1999_c20170717.csv)\n",
      "28-th out of 207 files is being processed (StormEvents_details-ftp_v1.0_d2013_c20170519.csv)\n",
      "29-th out of 207 files is being processed (StormEvents_details-ftp_v1.0_d1986_c20160223.csv)\n",
      "30-th out of 207 files is being processed (StormEvents_details-ftp_v1.0_d2004_c20170717.csv)\n",
      "31-th out of 207 files is being processed (StormEvents_locations-ftp_v1.0_d2009_c20180718.csv)\n",
      "32-th out of 207 files is being processed (StormEvents_details-ftp_v1.0_d1997_c20170717.csv)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py:3020: DtypeWarning: Columns (28) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33-th out of 207 files is being processed (StormEvents_locations-ftp_v1.0_d1969_c20170717.csv)\n",
      "34-th out of 207 files is being processed (StormEvents_details-ftp_v1.0_d2002_c20170717.csv)\n",
      "35-th out of 207 files is being processed (StormEvents_fatalities-ftp_v1.0_d1967_c20160223.csv)\n",
      "36-th out of 207 files is being processed (StormEvents_details-ftp_v1.0_d1955_c20160223.csv)\n",
      "37-th out of 207 files is being processed (StormEvents_locations-ftp_v1.0_d1970_c20160223.csv)\n",
      "38-th out of 207 files is being processed (StormEvents_fatalities-ftp_v1.0_d2016_c20180718.csv)\n",
      "39-th out of 207 files is being processed (StormEvents_fatalities-ftp_v1.0_d1984_c20170717.csv)\n",
      "40-th out of 207 files is being processed (StormEvents_details-ftp_v1.0_d1987_c20160223.csv)\n",
      "41-th out of 207 files is being processed (StormEvents_locations-ftp_v1.0_d1995_c20170522.csv)\n",
      "42-th out of 207 files is being processed (StormEvents_details-ftp_v1.0_d1981_c20170717.csv)\n",
      "43-th out of 207 files is being processed (StormEvents_locations-ftp_v1.0_d1956_c20170717.csv)\n",
      "44-th out of 207 files is being processed (StormEvents_details-ftp_v1.0_d1985_c20160223.csv)\n",
      "45-th out of 207 files is being processed (StormEvents_fatalities-ftp_v1.0_d1998_c20170717.csv)\n",
      "46-th out of 207 files is being processed (StormEvents_fatalities-ftp_v1.0_d2007_c20170717.csv)\n",
      "47-th out of 207 files is being processed (StormEvents_locations-ftp_v1.0_d1999_c20170717.csv)\n",
      "48-th out of 207 files is being processed (StormEvents_fatalities-ftp_v1.0_d1961_c20160223.csv)\n",
      "49-th out of 207 files is being processed (StormEvents_fatalities-ftp_v1.0_d1959_c20160223.csv)\n",
      "50-th out of 207 files is being processed (StormEvents_locations-ftp_v1.0_d1965_c20190301.csv)\n",
      "51-th out of 207 files is being processed (StormEvents_locations-ftp_v1.0_d2014_c20180718.csv)\n",
      "52-th out of 207 files is being processed (StormEvents_locations-ftp_v1.0_d1963_c20160223.csv)\n",
      "53-th out of 207 files is being processed (StormEvents_details-ftp_v1.0_d2008_c20180718.csv)\n",
      "54-th out of 207 files is being processed (StormEvents_details-ftp_v1.0_d1995_c20170522.csv)\n",
      "55-th out of 207 files is being processed (StormEvents_locations-ftp_v1.0_d2018_c20190325.csv)\n",
      "56-th out of 207 files is being processed (StormEvents_details-ftp_v1.0_d1970_c20160223.csv)\n",
      "57-th out of 207 files is being processed (StormEvents_details-ftp_v1.0_d1991_c20170717.csv)\n",
      "58-th out of 207 files is being processed (StormEvents_details-ftp_v1.0_d1956_c20170717.csv)\n",
      "59-th out of 207 files is being processed (StormEvents_fatalities-ftp_v1.0_d1999_c20170717.csv)\n",
      "60-th out of 207 files is being processed (StormEvents_locations-ftp_v1.0_d1975_c20160223.csv)\n",
      "61-th out of 207 files is being processed (StormEvents_locations-ftp_v1.0_d2011_c20180718.csv)\n",
      "62-th out of 207 files is being processed (StormEvents_locations-ftp_v1.0_d1998_c20170717.csv)\n",
      "63-th out of 207 files is being processed (StormEvents_locations-ftp_v1.0_d1951_c20160223.csv)\n",
      "64-th out of 207 files is being processed (StormEvents_details-ftp_v1.0_d1989_c20170717.csv)\n",
      "65-th out of 207 files is being processed (StormEvents_fatalities-ftp_v1.0_d1971_c20160223.csv)\n",
      "66-th out of 207 files is being processed (StormEvents_details-ftp_v1.0_d1977_c20160223.csv)\n",
      "67-th out of 207 files is being processed (StormEvents_locations-ftp_v1.0_d1997_c20170717.csv)\n",
      "68-th out of 207 files is being processed (StormEvents_locations-ftp_v1.0_d1960_c20160223.csv)\n",
      "69-th out of 207 files is being processed (StormEvents_fatalities-ftp_v1.0_d1994_c20170717.csv)\n",
      "70-th out of 207 files is being processed (StormEvents_locations-ftp_v1.0_d1974_c20160223.csv)\n",
      "71-th out of 207 files is being processed (StormEvents_details-ftp_v1.0_d1971_c20160223.csv)\n",
      "72-th out of 207 files is being processed (StormEvents_fatalities-ftp_v1.0_d1977_c20160223.csv)\n",
      "73-th out of 207 files is being processed (StormEvents_fatalities-ftp_v1.0_d2000_c20170717.csv)\n",
      "74-th out of 207 files is being processed (StormEvents_locations-ftp_v1.0_d1971_c20160223.csv)\n",
      "75-th out of 207 files is being processed (StormEvents_locations-ftp_v1.0_d2005_c20170717.csv)\n",
      "76-th out of 207 files is being processed (StormEvents_details-ftp_v1.0_d1980_c20170717.csv)\n",
      "77-th out of 207 files is being processed (StormEvents_details-ftp_v1.0_d2005_c20170717.csv)\n",
      "78-th out of 207 files is being processed (StormEvents_locations-ftp_v1.0_d1989_c20170717.csv)\n",
      "79-th out of 207 files is being processed (StormEvents_fatalities-ftp_v1.0_d1951_c20160223.csv)\n",
      "80-th out of 207 files is being processed (StormEvents_details-ftp_v1.0_d1953_c20160223.csv)\n",
      "81-th out of 207 files is being processed (StormEvents_locations-ftp_v1.0_d1986_c20160223.csv)\n",
      "82-th out of 207 files is being processed (StormEvents_locations-ftp_v1.0_d1990_c20170717.csv)\n",
      "83-th out of 207 files is being processed (StormEvents_locations-ftp_v1.0_d1987_c20160223.csv)\n",
      "84-th out of 207 files is being processed (StormEvents_details-ftp_v1.0_d2015_c20180525.csv)\n",
      "85-th out of 207 files is being processed (StormEvents_details-ftp_v1.0_d1950_c20170120.csv)\n",
      "86-th out of 207 files is being processed (StormEvents_details-ftp_v1.0_d1969_c20170717.csv)\n",
      "87-th out of 207 files is being processed (StormEvents_locations-ftp_v1.0_d1994_c20170717.csv)\n",
      "88-th out of 207 files is being processed (StormEvents_locations-ftp_v1.0_d1983_c20160223.csv)\n",
      "89-th out of 207 files is being processed (StormEvents_fatalities-ftp_v1.0_d1980_c20170717.csv)\n",
      "90-th out of 207 files is being processed (StormEvents_fatalities-ftp_v1.0_d1983_c20160223.csv)\n",
      "91-th out of 207 files is being processed (StormEvents_locations-ftp_v1.0_d2016_c20180718.csv)\n",
      "92-th out of 207 files is being processed (StormEvents_locations-ftp_v1.0_d1982_c20160223.csv)\n",
      "93-th out of 207 files is being processed (StormEvents_details-ftp_v1.0_d1972_c20181029.csv)\n",
      "94-th out of 207 files is being processed (StormEvents_fatalities-ftp_v1.0_d1970_c20160223.csv)\n",
      "95-th out of 207 files is being processed (StormEvents_details-ftp_v1.0_d2003_c20170717.csv)\n",
      "96-th out of 207 files is being processed (StormEvents_fatalities-ftp_v1.0_d1966_c20160223.csv)\n",
      "97-th out of 207 files is being processed (StormEvents_details-ftp_v1.0_d1966_c20160223.csv)\n",
      "98-th out of 207 files is being processed (StormEvents_fatalities-ftp_v1.0_d1955_c20160223.csv)\n",
      "99-th out of 207 files is being processed (StormEvents_fatalities-ftp_v1.0_d1990_c20170717.csv)\n",
      "100-th out of 207 files is being processed (StormEvents_details-ftp_v1.0_d1975_c20160223.csv)\n",
      "101-th out of 207 files is being processed (StormEvents_fatalities-ftp_v1.0_d1974_c20160223.csv)\n",
      "102-th out of 207 files is being processed (StormEvents_fatalities-ftp_v1.0_d1992_c20170717.csv)\n",
      "103-th out of 207 files is being processed (StormEvents_fatalities-ftp_v1.0_d1957_c20160223.csv)\n",
      "104-th out of 207 files is being processed (StormEvents_locations-ftp_v1.0_d2013_c20170519.csv)\n",
      "105-th out of 207 files is being processed (StormEvents_fatalities-ftp_v1.0_d1953_c20160223.csv)\n",
      "106-th out of 207 files is being processed (StormEvents_fatalities-ftp_v1.0_d2004_c20170717.csv)\n",
      "107-th out of 207 files is being processed (StormEvents_locations-ftp_v1.0_d2003_c20170717.csv)\n",
      "108-th out of 207 files is being processed (StormEvents_locations-ftp_v1.0_d1984_c20170717.csv)\n",
      "109-th out of 207 files is being processed (StormEvents_locations-ftp_v1.0_d1996_c20170717.csv)\n",
      "110-th out of 207 files is being processed (StormEvents_details-ftp_v1.0_d1974_c20160223.csv)\n",
      "111-th out of 207 files is being processed (StormEvents_details-ftp_v1.0_d1961_c20160223.csv)\n",
      "112-th out of 207 files is being processed (StormEvents_fatalities-ftp_v1.0_d2001_c20170717.csv)\n",
      "113-th out of 207 files is being processed (StormEvents_locations-ftp_v1.0_d1988_c20170717.csv)\n",
      "114-th out of 207 files is being processed (StormEvents_locations-ftp_v1.0_d2012_c20170519.csv)\n",
      "115-th out of 207 files is being processed (StormEvents_locations-ftp_v1.0_d1950_c20170120.csv)\n",
      "116-th out of 207 files is being processed (StormEvents_fatalities-ftp_v1.0_d1972_c20181029.csv)\n",
      "117-th out of 207 files is being processed (StormEvents_fatalities-ftp_v1.0_d1975_c20160223.csv)\n",
      "118-th out of 207 files is being processed (StormEvents_fatalities-ftp_v1.0_d1956_c20170717.csv)\n",
      "119-th out of 207 files is being processed (StormEvents_locations-ftp_v1.0_d1959_c20160223.csv)\n",
      "120-th out of 207 files is being processed (StormEvents_locations-ftp_v1.0_d1991_c20170717.csv)\n",
      "121-th out of 207 files is being processed (StormEvents_locations-ftp_v1.0_d1972_c20181029.csv)\n",
      "122-th out of 207 files is being processed (StormEvents_locations-ftp_v1.0_d1993_c20170717.csv)\n",
      "123-th out of 207 files is being processed (StormEvents_details-ftp_v1.0_d1982_c20160223.csv)\n",
      "124-th out of 207 files is being processed (StormEvents_details-ftp_v1.0_d1963_c20160223.csv)\n",
      "125-th out of 207 files is being processed (StormEvents_details-ftp_v1.0_d1952_c20170619.csv)\n",
      "126-th out of 207 files is being processed (StormEvents_details-ftp_v1.0_d1979_c20160223.csv)\n",
      "127-th out of 207 files is being processed (StormEvents_fatalities-ftp_v1.0_d1979_c20160223.csv)\n",
      "128-th out of 207 files is being processed (StormEvents_fatalities-ftp_v1.0_d1988_c20170717.csv)\n",
      "129-th out of 207 files is being processed (StormEvents_locations-ftp_v1.0_d1952_c20170619.csv)\n",
      "130-th out of 207 files is being processed (StormEvents_locations-ftp_v1.0_d1954_c20160223.csv)\n",
      "131-th out of 207 files is being processed (StormEvents_details-ftp_v1.0_d2007_c20170717.csv)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132-th out of 207 files is being processed (StormEvents_details-ftp_v1.0_d1976_c20160223.csv)\n",
      "133-th out of 207 files is being processed (StormEvents_details-ftp_v1.0_d2006_c20170717.csv)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py:3020: DtypeWarning: Columns (29,34,35,37) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134-th out of 207 files is being processed (StormEvents_details-ftp_v1.0_d2012_c20170519.csv)\n",
      "135-th out of 207 files is being processed (StormEvents_details-ftp_v1.0_d1990_c20170717.csv)\n",
      "136-th out of 207 files is being processed (StormEvents_fatalities-ftp_v1.0_d1952_c20170619.csv)\n",
      "137-th out of 207 files is being processed (StormEvents_locations-ftp_v1.0_d1973_c20160223.csv)\n",
      "138-th out of 207 files is being processed (StormEvents_details-ftp_v1.0_d2014_c20180718.csv)\n",
      "139-th out of 207 files is being processed (StormEvents_locations-ftp_v1.0_d1955_c20160223.csv)\n",
      "140-th out of 207 files is being processed (StormEvents_fatalities-ftp_v1.0_d1987_c20160223.csv)\n",
      "141-th out of 207 files is being processed (StormEvents_details-ftp_v1.0_d1959_c20160223.csv)\n",
      "142-th out of 207 files is being processed (StormEvents_fatalities-ftp_v1.0_d1950_c20170120.csv)\n",
      "143-th out of 207 files is being processed (StormEvents_details-ftp_v1.0_d1954_c20160223.csv)\n",
      "144-th out of 207 files is being processed (StormEvents_locations-ftp_v1.0_d1978_c20160223.csv)\n",
      "145-th out of 207 files is being processed (StormEvents_locations-ftp_v1.0_d1992_c20170717.csv)\n",
      "146-th out of 207 files is being processed (StormEvents_locations-ftp_v1.0_d2007_c20170717.csv)\n",
      "147-th out of 207 files is being processed (StormEvents_fatalities-ftp_v1.0_d1960_c20160223.csv)\n",
      "148-th out of 207 files is being processed (StormEvents_fatalities-ftp_v1.0_d1965_c20190301.csv)\n",
      "149-th out of 207 files is being processed (StormEvents_details-ftp_v1.0_d2009_c20180718.csv)\n",
      "150-th out of 207 files is being processed (StormEvents_locations-ftp_v1.0_d1961_c20160223.csv)\n",
      "151-th out of 207 files is being processed (StormEvents_locations-ftp_v1.0_d2015_c20180525.csv)\n",
      "152-th out of 207 files is being processed (StormEvents_locations-ftp_v1.0_d2008_c20180718.csv)\n",
      "153-th out of 207 files is being processed (StormEvents_locations-ftp_v1.0_d1958_c20160223.csv)\n",
      "154-th out of 207 files is being processed (StormEvents_locations-ftp_v1.0_d1953_c20160223.csv)\n",
      "155-th out of 207 files is being processed (StormEvents_fatalities-ftp_v1.0_d1997_c20170717.csv)\n",
      "156-th out of 207 files is being processed (StormEvents_locations-ftp_v1.0_d1966_c20160223.csv)\n",
      "157-th out of 207 files is being processed (StormEvents_details-ftp_v1.0_d1951_c20160223.csv)\n",
      "158-th out of 207 files is being processed (StormEvents_fatalities-ftp_v1.0_d1991_c20170717.csv)\n",
      "159-th out of 207 files is being processed (StormEvents_details-ftp_v1.0_d2017_c20190405.csv)\n",
      "160-th out of 207 files is being processed (StormEvents_locations-ftp_v1.0_d1964_c20160223.csv)\n",
      "161-th out of 207 files is being processed (StormEvents_fatalities-ftp_v1.0_d1986_c20160223.csv)\n",
      "162-th out of 207 files is being processed (StormEvents_fatalities-ftp_v1.0_d1968_c20160223.csv)\n",
      "163-th out of 207 files is being processed (StormEvents_details-ftp_v1.0_d1996_c20170717.csv)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py:3020: DtypeWarning: Columns (26,28) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164-th out of 207 files is being processed (StormEvents_details-ftp_v1.0_d1962_c20160223.csv)\n",
      "165-th out of 207 files is being processed (StormEvents_details-ftp_v1.0_d2000_c20170717.csv)\n",
      "166-th out of 207 files is being processed (StormEvents_fatalities-ftp_v1.0_d1958_c20160223.csv)\n",
      "167-th out of 207 files is being processed (StormEvents_details-ftp_v1.0_d1965_c20190301.csv)\n",
      "168-th out of 207 files is being processed (StormEvents_locations-ftp_v1.0_d1957_c20160223.csv)\n",
      "169-th out of 207 files is being processed (StormEvents_details-ftp_v1.0_d1964_c20160223.csv)\n",
      "170-th out of 207 files is being processed (StormEvents_details-ftp_v1.0_d2016_c20180718.csv)\n",
      "171-th out of 207 files is being processed (StormEvents_fatalities-ftp_v1.0_d2006_c20170717.csv)\n",
      "172-th out of 207 files is being processed (StormEvents_locations-ftp_v1.0_d1976_c20160223.csv)\n",
      "173-th out of 207 files is being processed (StormEvents_details-ftp_v1.0_d1967_c20160223.csv)\n",
      "174-th out of 207 files is being processed (StormEvents_fatalities-ftp_v1.0_d2018_c20190325.csv)\n",
      "175-th out of 207 files is being processed (StormEvents_details-ftp_v1.0_d2018_c20190325.csv)\n",
      "176-th out of 207 files is being processed (StormEvents_details-ftp_v1.0_d1983_c20160223.csv)\n",
      "177-th out of 207 files is being processed (StormEvents_details-ftp_v1.0_d1960_c20160223.csv)\n",
      "178-th out of 207 files is being processed (StormEvents_details-ftp_v1.0_d1978_c20160223.csv)\n",
      "179-th out of 207 files is being processed (StormEvents_fatalities-ftp_v1.0_d2009_c20180718.csv)\n",
      "180-th out of 207 files is being processed (StormEvents_fatalities-ftp_v1.0_d1989_c20170717.csv)\n",
      "181-th out of 207 files is being processed (StormEvents_locations-ftp_v1.0_d1967_c20160223.csv)\n",
      "182-th out of 207 files is being processed (StormEvents_details-ftp_v1.0_d1998_c20170717.csv)\n",
      "183-th out of 207 files is being processed (StormEvents_fatalities-ftp_v1.0_d2002_c20170717.csv)\n",
      "184-th out of 207 files is being processed (StormEvents_locations-ftp_v1.0_d1981_c20170717.csv)\n",
      "185-th out of 207 files is being processed (StormEvents_locations-ftp_v1.0_d2000_c20170717.csv)\n",
      "186-th out of 207 files is being processed (StormEvents_fatalities-ftp_v1.0_d1973_c20160223.csv)\n",
      "187-th out of 207 files is being processed (StormEvents_fatalities-ftp_v1.0_d1976_c20160223.csv)\n",
      "188-th out of 207 files is being processed (StormEvents_fatalities-ftp_v1.0_d1954_c20160223.csv)\n",
      "189-th out of 207 files is being processed (StormEvents_fatalities-ftp_v1.0_d1969_c20170717.csv)\n",
      "190-th out of 207 files is being processed (StormEvents_details-ftp_v1.0_d1992_c20170717.csv)\n",
      "191-th out of 207 files is being processed (StormEvents_fatalities-ftp_v1.0_d2017_c20190405.csv)\n",
      "192-th out of 207 files is being processed (StormEvents_fatalities-ftp_v1.0_d1995_c20170522.csv)\n",
      "193-th out of 207 files is being processed (StormEvents_fatalities-ftp_v1.0_d2008_c20180718.csv)\n",
      "194-th out of 207 files is being processed (StormEvents_fatalities-ftp_v1.0_d2005_c20170717.csv)\n",
      "195-th out of 207 files is being processed (StormEvents_fatalities-ftp_v1.0_d1978_c20160223.csv)\n",
      "196-th out of 207 files is being processed (StormEvents_fatalities-ftp_v1.0_d2003_c20170717.csv)\n",
      "197-th out of 207 files is being processed (StormEvents_details-ftp_v1.0_d1973_c20160223.csv)\n",
      "198-th out of 207 files is being processed (StormEvents_fatalities-ftp_v1.0_d2013_c20170519.csv)\n",
      "199-th out of 207 files is being processed (StormEvents_details-ftp_v1.0_d2010_c20170726.csv)\n",
      "200-th out of 207 files is being processed (StormEvents_details-ftp_v1.0_d1984_c20170717.csv)\n",
      "201-th out of 207 files is being processed (StormEvents_locations-ftp_v1.0_d1962_c20160223.csv)\n",
      "202-th out of 207 files is being processed (StormEvents_fatalities-ftp_v1.0_d1962_c20160223.csv)\n",
      "203-th out of 207 files is being processed (StormEvents_locations-ftp_v1.0_d2001_c20170717.csv)\n",
      "204-th out of 207 files is being processed (StormEvents_fatalities-ftp_v1.0_d1996_c20170717.csv)\n",
      "205-th out of 207 files is being processed (StormEvents_fatalities-ftp_v1.0_d1993_c20170717.csv)\n",
      "206-th out of 207 files is being processed (StormEvents_details-ftp_v1.0_d1994_c20170717.csv)\n",
      "207-th out of 207 files is being processed (StormEvents_locations-ftp_v1.0_d2010_c20170726.csv)\n",
      "\n",
      "\n",
      "       Done ! \n",
      "\n",
      "details    : 69\n",
      "locations  : 69\n",
      "fatalities : 69\n",
      "else_count : 0\n"
     ]
    }
   ],
   "source": [
    "########################\n",
    "##    Reading data    ##\n",
    "########################\n",
    "\n",
    "data = {}\n",
    "details = 0\n",
    "locations = 0\n",
    "fatalities = 0\n",
    "else_count = 0\n",
    "\n",
    "file_count = len(os.listdir(csv_data_dir))\n",
    "\n",
    "for i, file_name in enumerate(os.listdir(csv_data_dir)):\n",
    "    print('{}-th out of {} files is being processed ({})'.format(i+1, file_count, file_name))\n",
    "    assert file_name[-4:]=='.csv', '\\n\\n Foreign file format encountered !!! \\n\\n'\n",
    "    assert file_name[:11]=='StormEvents', '\\n\\n Foreign file name encountered !!! \\n\\n'\n",
    "    \n",
    "    year = file_name[-18:-14]\n",
    "    if year not in data:\n",
    "        data[year] = {}\n",
    "    \n",
    "    if file_name[12:19]=='details':\n",
    "        data[year]['details'] = pd.read_csv(os.path.join(csv_data_dir, file_name))\n",
    "        details += 1\n",
    "    elif file_name[12:21]=='locations':\n",
    "        data[year]['locations'] = pd.read_csv(os.path.join(csv_data_dir, file_name))\n",
    "        locations += 1\n",
    "    elif file_name[12:22]=='fatalities':\n",
    "        data[year]['fatalities'] = pd.read_csv(os.path.join(csv_data_dir, file_name))\n",
    "        fatalities += 1\n",
    "    else:\n",
    "        raise Exception('\\n\\n Foreign file encountered !!! \\n\\n')\n",
    "\n",
    "print('\\n\\n       Done ! \\n')\n",
    "print('details    :', details)\n",
    "print('locations  :', locations)\n",
    "print('fatalities :', fatalities)\n",
    "print('else_count :', else_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['1950']['details'].info()\n",
    "BEGIN_YEARMONTH, STATE, STATE_FIPS,\n",
    "INJURIES_DIRECT, INJURIES_INDIRECT, \n",
    "DEATHS_DIRECT, DEATHS_INDIRECT, \n",
    "DAMAGE_PROPERTY, DAMAGE_CROPS, \n",
    "EVENT_TYPE, MAGNITUDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1950 :\t0 events with NaN STATE from 223\n",
      "1951 :\t0 events with NaN STATE from 269\n",
      "1952 :\t0 events with NaN STATE from 272\n",
      "1953 :\t0 events with NaN STATE from 492\n",
      "1954 :\t0 events with NaN STATE from 609\n",
      "1955 :\t0 events with NaN STATE from 1413\n",
      "1956 :\t0 events with NaN STATE from 1703\n",
      "1957 :\t0 events with NaN STATE from 2184\n",
      "1958 :\t0 events with NaN STATE from 2213\n",
      "1959 :\t0 events with NaN STATE from 1813\n",
      "1960 :\t0 events with NaN STATE from 1945\n",
      "1961 :\t0 events with NaN STATE from 2246\n",
      "1962 :\t0 events with NaN STATE from 2389\n",
      "1963 :\t0 events with NaN STATE from 1968\n",
      "1964 :\t0 events with NaN STATE from 2348\n",
      "1965 :\t0 events with NaN STATE from 2835\n",
      "1966 :\t0 events with NaN STATE from 2388\n",
      "1967 :\t0 events with NaN STATE from 2688\n",
      "1968 :\t0 events with NaN STATE from 3312\n",
      "1969 :\t0 events with NaN STATE from 2926\n",
      "1970 :\t0 events with NaN STATE from 3215\n",
      "1971 :\t0 events with NaN STATE from 3471\n",
      "1972 :\t0 events with NaN STATE from 2171\n",
      "1973 :\t0 events with NaN STATE from 4453\n",
      "1974 :\t0 events with NaN STATE from 5375\n",
      "1975 :\t0 events with NaN STATE from 4975\n",
      "1976 :\t0 events with NaN STATE from 3768\n",
      "1977 :\t0 events with NaN STATE from 3728\n",
      "1978 :\t0 events with NaN STATE from 3657\n",
      "1979 :\t0 events with NaN STATE from 4279\n",
      "1980 :\t0 events with NaN STATE from 6136\n",
      "1981 :\t0 events with NaN STATE from 4517\n",
      "1982 :\t0 events with NaN STATE from 7126\n",
      "1983 :\t0 events with NaN STATE from 8322\n",
      "1984 :\t0 events with NaN STATE from 7335\n",
      "1985 :\t0 events with NaN STATE from 7979\n",
      "1986 :\t0 events with NaN STATE from 8725\n",
      "1987 :\t0 events with NaN STATE from 7363\n",
      "1988 :\t0 events with NaN STATE from 7257\n",
      "1989 :\t0 events with NaN STATE from 10407\n",
      "1990 :\t0 events with NaN STATE from 10945\n",
      "1991 :\t0 events with NaN STATE from 12516\n",
      "1992 :\t0 events with NaN STATE from 13534\n",
      "1993 :\t0 events with NaN STATE from 8664\n",
      "1994 :\t0 events with NaN STATE from 15627\n",
      "1995 :\t0 events with NaN STATE from 20461\n",
      "1996 :\t0 events with NaN STATE from 48561\n",
      "1997 :\t0 events with NaN STATE from 41991\n",
      "1998 :\t0 events with NaN STATE from 50973\n",
      "1999 :\t0 events with NaN STATE from 46383\n",
      "2000 :\t0 events with NaN STATE from 52007\n",
      "2001 :\t0 events with NaN STATE from 48875\n",
      "2002 :\t0 events with NaN STATE from 50936\n",
      "2003 :\t1 events with NaN STATE from 52956\n",
      "2004 :\t0 events with NaN STATE from 52409\n",
      "2005 :\t0 events with NaN STATE from 53976\n",
      "2006 :\t0 events with NaN STATE from 56400\n",
      "2007 :\t0 events with NaN STATE from 59010\n",
      "2008 :\t0 events with NaN STATE from 71190\n",
      "2009 :\t0 events with NaN STATE from 57398\n",
      "2010 :\t0 events with NaN STATE from 62804\n",
      "2011 :\t0 events with NaN STATE from 79091\n",
      "2012 :\t0 events with NaN STATE from 64503\n",
      "2013 :\t0 events with NaN STATE from 59985\n",
      "2014 :\t0 events with NaN STATE from 59465\n",
      "2015 :\t0 events with NaN STATE from 57788\n",
      "2016 :\t0 events with NaN STATE from 56003\n",
      "2017 :\t0 events with NaN STATE from 56999\n",
      "2018 :\t0 events with NaN STATE from 61742\n"
     ]
    }
   ],
   "source": [
    "#########################################################\n",
    "##   Counting all the events not having STATE column   ##\n",
    "#########################################################\n",
    "\n",
    "for year in range(int(min(data.keys())), int(max(data.keys()))+1):\n",
    "    isna = data[str(year)]['details'].STATE.isna()\n",
    "    print(year,':',end='\\t')\n",
    "    print('{} events with NaN STATE from {}'.format(np.sum(isna), isna.shape[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1950 :\t223 events occured\n",
      "     : \t223 non-NaN containing events\n",
      "\n",
      "1951 :\t269 events occured\n",
      "     : \t269 non-NaN containing events\n",
      "\n",
      "1952 :\t272 events occured\n",
      "     : \t272 non-NaN containing events\n",
      "\n",
      "1953 :\t492 events occured\n",
      "     : \t492 non-NaN containing events\n",
      "\n",
      "1954 :\t609 events occured\n",
      "     : \t609 non-NaN containing events\n",
      "\n",
      "1955 :\t1413 events occured\n",
      "     : \t1413 non-NaN containing events\n",
      "\n",
      "1956 :\t1703 events occured\n",
      "     : \t1703 non-NaN containing events\n",
      "\n",
      "1957 :\t2184 events occured\n",
      "     : \t2184 non-NaN containing events\n",
      "\n",
      "1958 :\t2213 events occured\n",
      "     : \t2213 non-NaN containing events\n",
      "\n",
      "1959 :\t1813 events occured\n",
      "     : \t1813 non-NaN containing events\n",
      "\n",
      "1960 :\t1945 events occured\n",
      "     : \t1945 non-NaN containing events\n",
      "\n",
      "1961 :\t2246 events occured\n",
      "     : \t2246 non-NaN containing events\n",
      "\n",
      "1962 :\t2389 events occured\n",
      "     : \t2389 non-NaN containing events\n",
      "\n",
      "1963 :\t1968 events occured\n",
      "     : \t1968 non-NaN containing events\n",
      "\n",
      "1964 :\t2348 events occured\n",
      "     : \t2348 non-NaN containing events\n",
      "\n",
      "1965 :\t2835 events occured\n",
      "     : \t2835 non-NaN containing events\n",
      "\n",
      "1966 :\t2388 events occured\n",
      "     : \t2388 non-NaN containing events\n",
      "\n",
      "1967 :\t2688 events occured\n",
      "     : \t2688 non-NaN containing events\n",
      "\n",
      "1968 :\t3312 events occured\n",
      "     : \t3312 non-NaN containing events\n",
      "\n",
      "1969 :\t2926 events occured\n",
      "     : \t2926 non-NaN containing events\n",
      "\n",
      "1970 :\t3215 events occured\n",
      "     : \t3215 non-NaN containing events\n",
      "\n",
      "1971 :\t3471 events occured\n",
      "     : \t3471 non-NaN containing events\n",
      "\n",
      "1972 :\t2171 events occured\n",
      "     : \t2171 non-NaN containing events\n",
      "\n",
      "1973 :\t4453 events occured\n",
      "     : \t4453 non-NaN containing events\n",
      "\n",
      "1974 :\t5375 events occured\n",
      "     : \t5375 non-NaN containing events\n",
      "\n",
      "1975 :\t4975 events occured\n",
      "     : \t4975 non-NaN containing events\n",
      "\n",
      "1976 :\t3768 events occured\n",
      "     : \t3768 non-NaN containing events\n",
      "\n",
      "1977 :\t3728 events occured\n",
      "     : \t3728 non-NaN containing events\n",
      "\n",
      "1978 :\t3657 events occured\n",
      "     : \t3657 non-NaN containing events\n",
      "\n",
      "1979 :\t4279 events occured\n",
      "     : \t4279 non-NaN containing events\n",
      "\n",
      "1980 :\t6136 events occured\n",
      "     : \t6136 non-NaN containing events\n",
      "\n",
      "1981 :\t4517 events occured\n",
      "     : \t4517 non-NaN containing events\n",
      "\n",
      "1982 :\t7126 events occured\n",
      "     : \t7126 non-NaN containing events\n",
      "\n",
      "1983 :\t8322 events occured\n",
      "     : \t8322 non-NaN containing events\n",
      "\n",
      "1984 :\t7335 events occured\n",
      "     : \t7335 non-NaN containing events\n",
      "\n",
      "1985 :\t7979 events occured\n",
      "     : \t7979 non-NaN containing events\n",
      "\n",
      "1986 :\t8725 events occured\n",
      "     : \t8725 non-NaN containing events\n",
      "\n",
      "1987 :\t7363 events occured\n",
      "     : \t7363 non-NaN containing events\n",
      "\n",
      "1988 :\t7257 events occured\n",
      "     : \t7257 non-NaN containing events\n",
      "\n",
      "1989 :\t10407 events occured\n",
      "     : \t10407 non-NaN containing events\n",
      "\n",
      "1990 :\t10945 events occured\n",
      "     : \t10945 non-NaN containing events\n",
      "\n",
      "1991 :\t12516 events occured\n",
      "     : \t12516 non-NaN containing events\n",
      "\n",
      "1992 :\t13534 events occured\n",
      "     : \t13534 non-NaN containing events\n",
      "\n",
      "1993 :\t8664 events occured\n",
      "     : \t8664 non-NaN containing events\n",
      "\n",
      "1994 :\t15627 events occured\n",
      "     : \t15627 non-NaN containing events\n",
      "\n",
      "1995 :\t20461 events occured\n",
      "     : \t20461 non-NaN containing events\n",
      "\n",
      "1996 :\t48561 events occured\n",
      "     : \t48561 non-NaN containing events\n",
      "\n",
      "1997 :\t41991 events occured\n",
      "     : \t41991 non-NaN containing events\n",
      "\n",
      "1998 :\t50973 events occured\n",
      "     : \t50973 non-NaN containing events\n",
      "\n",
      "1999 :\t46383 events occured\n",
      "     : \t46383 non-NaN containing events\n",
      "\n",
      "2000 :\t52007 events occured\n",
      "     : \t52007 non-NaN containing events\n",
      "\n",
      "2001 :\t48875 events occured\n",
      "     : \t48875 non-NaN containing events\n",
      "\n",
      "2002 :\t50936 events occured\n",
      "     : \t50936 non-NaN containing events\n",
      "\n",
      "2003 :\t52956 events occured\n",
      "     : \t52955 non-NaN containing events\n",
      "\n",
      "2004 :\t52409 events occured\n",
      "     : \t52409 non-NaN containing events\n",
      "\n",
      "2005 :\t53976 events occured\n",
      "     : \t53976 non-NaN containing events\n",
      "\n",
      "2006 :\t56400 events occured\n",
      "     : \t56400 non-NaN containing events\n",
      "\n",
      "2007 :\t59010 events occured\n",
      "     : \t59010 non-NaN containing events\n",
      "\n",
      "2008 :\t71190 events occured\n",
      "     : \t71190 non-NaN containing events\n",
      "\n",
      "2009 :\t57398 events occured\n",
      "     : \t57398 non-NaN containing events\n",
      "\n",
      "2010 :\t62804 events occured\n",
      "     : \t62804 non-NaN containing events\n",
      "\n",
      "2011 :\t79091 events occured\n",
      "     : \t79091 non-NaN containing events\n",
      "\n",
      "2012 :\t64503 events occured\n",
      "     : \t64503 non-NaN containing events\n",
      "\n",
      "2013 :\t59985 events occured\n",
      "     : \t59985 non-NaN containing events\n",
      "\n",
      "2014 :\t59465 events occured\n",
      "     : \t59465 non-NaN containing events\n",
      "\n",
      "2015 :\t57788 events occured\n",
      "     : \t57788 non-NaN containing events\n",
      "\n",
      "2016 :\t56003 events occured\n",
      "     : \t56003 non-NaN containing events\n",
      "\n",
      "2017 :\t56999 events occured\n",
      "     : \t56999 non-NaN containing events\n",
      "\n",
      "2018 :\t61742 events occured\n",
      "     : \t61742 non-NaN containing events\n",
      "\n",
      "\n",
      "\n",
      " Done ! \n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1533686 entries, 0 to 61741\n",
      "Data columns (total 3 columns):\n",
      "STATE              1533686 non-null object\n",
      "EVENT_TYPE         1533686 non-null object\n",
      "BEGIN_YEARMONTH    1533686 non-null int64\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 46.8+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATE</th>\n",
       "      <th>EVENT_TYPE</th>\n",
       "      <th>BEGIN_YEARMONTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OKLAHOMA</td>\n",
       "      <td>Tornado</td>\n",
       "      <td>195004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEXAS</td>\n",
       "      <td>Tornado</td>\n",
       "      <td>195004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PENNSYLVANIA</td>\n",
       "      <td>Tornado</td>\n",
       "      <td>195007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PENNSYLVANIA</td>\n",
       "      <td>Tornado</td>\n",
       "      <td>195007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PENNSYLVANIA</td>\n",
       "      <td>Tornado</td>\n",
       "      <td>195007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          STATE EVENT_TYPE  BEGIN_YEARMONTH\n",
       "0      OKLAHOMA    Tornado           195004\n",
       "1         TEXAS    Tornado           195004\n",
       "2  PENNSYLVANIA    Tornado           195007\n",
       "3  PENNSYLVANIA    Tornado           195007\n",
       "4  PENNSYLVANIA    Tornado           195007"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##########################\n",
    "##    Filtering data    ##\n",
    "##########################\n",
    "\n",
    "filtered_data = []\n",
    "for year in range(int(min(data.keys())), int(max(data.keys()))+1):\n",
    "    print(year,':',end='\\t')\n",
    "    year_data = data[str(year)]['details'][['STATE', 'EVENT_TYPE', 'BEGIN_YEARMONTH']]\n",
    "    print('{} events occured'.format(year_data.shape[0]))\n",
    "    year_data = year_data.loc[year_data.dropna().index]\n",
    "    print('     : \\t{} non-NaN containing events'.format(year_data.shape[0]),end='\\n\\n')\n",
    "    filtered_data.append(year_data)\n",
    "\n",
    "filtered_data = pd.concat(filtered_data)\n",
    "print('\\n\\n Done ! \\n\\n')\n",
    "print(filtered_data.info())\n",
    "filtered_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATE</th>\n",
       "      <th>EVENT_TYPE</th>\n",
       "      <th>BEGIN_YEARMONTH</th>\n",
       "      <th>DATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OKLAHOMA</td>\n",
       "      <td>Tornado</td>\n",
       "      <td>195004</td>\n",
       "      <td>1950-04-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEXAS</td>\n",
       "      <td>Tornado</td>\n",
       "      <td>195004</td>\n",
       "      <td>1950-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PENNSYLVANIA</td>\n",
       "      <td>Tornado</td>\n",
       "      <td>195007</td>\n",
       "      <td>1950-07-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PENNSYLVANIA</td>\n",
       "      <td>Tornado</td>\n",
       "      <td>195007</td>\n",
       "      <td>1950-07-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PENNSYLVANIA</td>\n",
       "      <td>Tornado</td>\n",
       "      <td>195007</td>\n",
       "      <td>1950-07-19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          STATE EVENT_TYPE  BEGIN_YEARMONTH        DATE\n",
       "0      OKLAHOMA    Tornado           195004  1950-04-06\n",
       "1         TEXAS    Tornado           195004  1950-04-01\n",
       "2  PENNSYLVANIA    Tornado           195007  1950-07-21\n",
       "3  PENNSYLVANIA    Tornado           195007  1950-07-25\n",
       "4  PENNSYLVANIA    Tornado           195007  1950-07-19"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##############################\n",
    "##    Adding DATE column    ##\n",
    "##############################\n",
    "\n",
    "filtered_data['DATE'] = filtered_data.BEGIN_YEARMONTH.apply(\n",
    "    lambda date: \n",
    "    datetime.date(date//100, date%100, np.random.randint(1,29))\n",
    ")\n",
    "filtered_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATE</th>\n",
       "      <th>EVENT_TYPE</th>\n",
       "      <th>BEGIN_YEARMONTH</th>\n",
       "      <th>DATE</th>\n",
       "      <th>DIST_FROM_START</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OKLAHOMA</td>\n",
       "      <td>Tornado</td>\n",
       "      <td>195004</td>\n",
       "      <td>1950-04-06</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEXAS</td>\n",
       "      <td>Tornado</td>\n",
       "      <td>195004</td>\n",
       "      <td>1950-04-01</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PENNSYLVANIA</td>\n",
       "      <td>Tornado</td>\n",
       "      <td>195007</td>\n",
       "      <td>1950-07-21</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PENNSYLVANIA</td>\n",
       "      <td>Tornado</td>\n",
       "      <td>195007</td>\n",
       "      <td>1950-07-25</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PENNSYLVANIA</td>\n",
       "      <td>Tornado</td>\n",
       "      <td>195007</td>\n",
       "      <td>1950-07-19</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          STATE EVENT_TYPE  BEGIN_YEARMONTH        DATE  DIST_FROM_START\n",
       "0      OKLAHOMA    Tornado           195004  1950-04-06               84\n",
       "1         TEXAS    Tornado           195004  1950-04-01               79\n",
       "2  PENNSYLVANIA    Tornado           195007  1950-07-21              190\n",
       "3  PENNSYLVANIA    Tornado           195007  1950-07-25              194\n",
       "4  PENNSYLVANIA    Tornado           195007  1950-07-19              188"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###########################################################\n",
    "##   Froming DIST_FROM_START column for fast splitting   ##\n",
    "###########################################################\n",
    "\n",
    "start = filtered_data.DATE.min()\n",
    "filtered_data['DIST_FROM_START'] = filtered_data.DATE.apply(lambda x: (x-start).days)\n",
    "filtered_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "##    Saving data    ##\n",
    "#######################\n",
    "\n",
    "filtered_data.to_pickle('filtered_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
